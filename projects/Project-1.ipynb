{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project-1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9qv6dWZPsroB","colab_type":"text"},"source":["# Project 1\n","Complete each of the below exercises. You should write your code only in between \n","\n","  ########## Your Code goes here #############\n","  \n","  #your code\n","  \n","  #######################################\n","  \n","Do not change any other code in the given functions. You can create new code cells to try things however before you submit the project please delete them. \n","\n","You are provided test functions. In order to be able to run the tests you should run the code cell below everytime you open this notebook or reset the runtime. \n","  \n"," \n","  "]},{"cell_type":"code","metadata":{"id":"bsaUovntxj-E","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import os \n","\n","if not os.path.isdir('MATH448001'):\n","    !git clone https://github.com/CihanSoylu/MATH448001.git\n","\n","from MATH448001.project_tests import project_1_tests\n","from MATH448001.project_utils import project_1_utils"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pv6W34NwNSjn","colab_type":"text"},"source":["# Exercise 1 (5 points)\n","\n","Write a function that takes a 2D numpy array as its argument and returns the average of the columns as an array. For example if the input array is `[[1,2],[3,4]]`, then the function will return `[2, 3]` since the average of the first column is (1+3)/2=2 and the second column is (2+4)/2=3.\n","\n","Hint: Use [`np.mean()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html). "]},{"cell_type":"code","metadata":{"id":"Rnmr6j0NPkWV","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def column_means(arr):\n","  \n","    ########## Your Code goes here #############\n","\n","    \n","    ############################################\n","    \n","    return column_means \n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQ8Yt_rgYXL0","colab_type":"code","colab":{}},"source":["project_1_tests.test_column_means(column_means)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l9E2Gt6PPGTq","colab_type":"text"},"source":["# Exercise 2 (10 points)\n","\n","Implement a function that takes an array and a threshold value as arguments and return an array where all the values of the input array above the threshold are replaced by the threshold value. \n","For example if the input array is `[[5,2],[3,4]]`, threshold = 3 then the function will return `[[3,2],[3,3]]`"]},{"cell_type":"code","metadata":{"id":"Tc_UadcRO4TN","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def cutoff(arr, threshold):\n","  \n","    ########## Your Code goes here #############\n","    \n","    ############################################  \n","    \n","    return arr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_oR-nWSdNGC","colab_type":"code","colab":{}},"source":["project_1_tests.test_cutoff(cutoff)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KyGlJ9naRPL0","colab_type":"text"},"source":["# Exercise 3 (5 points)\n","\n","Implement a function that takes a 2D array as its argument and returns the indices of the maximum values of each row as an array. For example if the input array is `[[5,2],[3,4]]`, then the function will return `[0,1]` since the the max value in the first row (which is 5) is at index 0 and the max value in the second row (which is 4) is at index 1.  \n","\n","Hint: Check out [`np.argmax()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html)"]},{"cell_type":"code","metadata":{"id":"ZAjj3UdTQBlO","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def find_max_index(arr):\n","  \n","    ########## Your Code goes here #############\n","\n","    ############################################ \n","    \n","    return max_indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2Pb9aUbfvlY","colab_type":"code","colab":{}},"source":["project_1_tests.test_max_index(find_max_index)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RGyIDQmMZPen","colab_type":"text"},"source":["# Exercise 4 (10 points)\n","\n","Implement a function that takes an array `W` of shape (m,n), an array `x` of shape (1,m) and an array `b` of shape (1,n) and returns the result of the following operation\n","$$\n","z = xW + b\n","$$\n","For example if \n","$$\n","W = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\quad x = \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\quad  b = \\begin{bmatrix} 3 & -1 \\end{bmatrix}\n","$$\n","then \n","$$\n","z = \\begin{bmatrix} 7 & 5 \\end{bmatrix}\n","$$\n","\n","Hint: Check out [`np.matmul()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html)"]},{"cell_type":"code","metadata":{"id":"0aqqbQY5SQ4Q","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def linear(W, x, b):\n","    \n","    ########## Your Code goes here #############\n","\n","    \n","    ############################################\n","    \n","    return z"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dfzXVKGE63ON","colab":{}},"source":["project_1_tests.test_linear(linear)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8LSzq-DSN6O","colab_type":"text"},"source":["# Exercise 5 (5 points)\n","\n","Implement a function that takes two integer arguments n and m and returns a random numpy array of shape (n,m) where the entries are sampled from a uniform distribution over $[-1,1]$. \n","\n","Hint: Take a look at [here](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html) to see the available probability distributions in numpy.  "]},{"cell_type":"code","metadata":{"id":"MXhBP7Cc0nM-","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def uniform_matrix(n,m):\n","\n","    np.random.seed(seed = 1)\n","\n","    ########## Your Code goes here #############\n","\n","    \n","    ############################################\n","\n","    return matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGlQBd2MTgMT","colab_type":"code","colab":{}},"source":["project_1_tests.test_uniform_matrix(uniform_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0p0UnM2smSW","colab_type":"text"},"source":["# Exercise 6 (5 points)\n","\n","Implement a function that takes two vectors (1D numpy arrays) in $\\mathbb{R}^n$ as its arguments and returns True if these vectors are orthogonal and False otherwise. "]},{"cell_type":"code","metadata":{"id":"lA_gNdQIs4ry","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def is_orthogonal(v1, v2):\n","\n","    ########## Your Code goes here #############\n","\n","\n","\n","    ############################################\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjL36RzOtKNK","colab_type":"code","colab":{}},"source":["project_1_tests.test_orthogonal(is_orthogonal)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mp_HnEBdt3cx","colab_type":"text"},"source":["# Exercise 7 (5 points)\n","\n","An $n\\times n$ matrix is called an orthogonal matrix if its columns form an **orthonormal** basis for $\\mathbb{R}^n$. This implies that $A$ is orthogonal if and only if\n","$$\n","A^{-1} = A^T\n","$$\n","if and only if \n","$$\n","A^TA = AA^T = I\n","$$\n","Example: For any $\\theta$, the matrix \n","$$\n","\\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}\n","$$\n","is an orthogonal matrix. \n","Implement a function that takes $\\theta$ as its argument and returns the above orthogonal matrix as a 2D numpy array. "]},{"cell_type":"code","metadata":{"id":"_oLLBOOHvoMe","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def rotation(theta):\n","\n","    ########## Your Code goes here #############\n","\n","    ############################################\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHCAwxSKwoCg","colab_type":"code","colab":{}},"source":["project_1_tests.test_rotation(rotation)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PqGuNPBczyn_","colab_type":"text"},"source":["# Exercise 8 (5 points)\n","\n","A symmetric matrix is a matrix $A$ such that $A^T = A$. Hence it is necessarily a square matrix. Every real symmetric matrix is orthogonally diagonalizable: If $A$ is an $n\\times n$ real symmetric matrix, then there exists an eigendecomposition \n","$$\n","A = P D P^T\n","$$\n","where \n"," - $D$ is a diagonal matrix with diagonal entries are the eigenvalues of $A$\n"," - $P$ is an orthogonal matrix with columns are the eigenvectors of $A$. The columns of $P$ form an orthonormal basis for $\\mathbb{R}^n$. \n","\n","Implement a function that takes a real symmetric matrix $A$ (a 2D numpy array) as its argument and returns the matrices $D$ and $P$ in its eigendecomposition above. \n","\n","Hint: Use `np.linalg.eig()` function. "]},{"cell_type":"code","metadata":{"id":"xf2N8Apw0BIc","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def eigendecomposition(A):\n","\n","    if not (A.T == A).all():\n","        print(\"The matrix is not symmetric\")\n","    else:    \n","        ########## Your Code goes here #############\n","\n","        ############################################\n","\n","        return D, P"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ug3qsPpXzSqY","colab_type":"code","colab":{}},"source":["project_1_tests.test_eigendecomposition(eigendecomposition)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmaieJvpPV5U","colab_type":"text"},"source":["# Exercise 9 (5 points)\n","\n","Implement a function that takes an $m\\times n$ matrix as its argument and returns its the Singular Value Decomposition: \n","\n","Let $A$ be an $m\\times n$ matrix. Then $A^TA$ is an $n\\times n$ symmetric matrix and so it is orthogonally diagonalizable, i.e. there exists an orthogonal matrix $P$ and a diagonal matrix $D$ such that\n","$$\n","A^TA = PDP^T\n","$$\n","The columns of the matrix $P$ are the orthonormal eigenvectors of $A^TA$ and the diagonal entries of $D$ are the eigenvalues of $A^TA$. Let $\\{v_1, \\ldots, v_n \\}$ be an orthonormal basis consisting of eigenvectors of $A^TA$ and $\\lambda_1. \\ldots, \\lambda_n$ are the associated eigenvalues. Then \n","$$\n","|| Av_i||^2 = (Av_i)^TAv_i = v_i^TA^TAv_i = v_i^T\\lambda_iv_i = \\lambda_i\n","$$\n","so the eigenvalues of $A^TA$ are all nonnegative and by reordering, if necessary, we may assume\n","$$\n","\\lambda_1 \\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_n \\geq 0\n","$$\n","The square root of the eigenvalues of $A^TA$ are called **singular  values of $A$** and denoted as $\\sigma_i$. So \n","$$\n","\\sigma_i = \\sqrt{\\lambda_i} = ||Av_i||\n","$$\n","Suppose $A$ has $r$ nonzero singular values. Hence\n","$$\n","\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r > 0\n","$$\n","Normalize each $Av_i$ and define\n","$$\n","u_i = \\frac{1}{||Av_i||}Av_i = \\frac{1}{\\sigma_i}Av_i \\quad i = 1, \\ldots, r\n","$$\n","Extend $\\{u_1, \\ldots, u_r\\}$ to an orthonormal basis $\\{u_1, \\ldots, u_m\\}$ of $\\mathbb{R}^m$ and let\n","$$\n","U = [u_1, \\ldots, u_m] \\quad V = [v_1, \\ldots, v_n]\n","$$\n","Then the Singular Value Decomposition of $A$ is given by\n","$$\n","A = U\\Sigma V^T\n","$$\n","where $\\Sigma$ is the $m\\times n$ matrix defined as\n","$$\n","\\Sigma = \\begin{bmatrix}\n","D & 0 \\\\\n","0 & 0\n","\\end{bmatrix}\n","$$\n","and $D = diag(\\sigma_1, \\sigma_2, \\ldots, \\sigma_r)$.\n","\n","Implement a function that takes a real valued matrix $A$ and returns the matrices $U$, $V$ and the singular values in its Singular Value Decomposition. \n","\n","Hint: Take a look at [`np.linalg.svd()`](https://numpy.org/doc/1.17/reference/generated/numpy.linalg.svd.html#numpy.linalg.svd)\n","Make sure you understand what `np.linalg.svd()` returns. You may need to use transpose. For a 2D numpy array A, the transpose is simply A.T "]},{"cell_type":"code","metadata":{"id":"J2VJDVykDVex","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def svd(A):\n","    ########## Your Code goes here #############\n","\n","\n","    ############################################\n","\n","    return U, V, singular_values\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVGz6W8200tB","colab_type":"code","colab":{}},"source":["project_1_tests.test_svd(svd)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B8SozJiuGRLm","colab_type":"text"},"source":["# Exercise 10 (5 points)\n","\n","A Bernoulli random variable is a discrete random variable with two possible values 0 and 1. So the probability distribution is completely determined by a single parameter $p$, the probability that $X$ takes the value 1. Hence $$\\mathbb{P}(X = 1) = p$$ and $$\\mathbb{P}(X = 0) = 1- p$$ \n","You can think of this as a single toss of a possibly unfair coin. \n","\n","A Binomial random variable $X$ with parameters $n$ and $p$ is defined as the sum of $n$ independent, identically distributed (iid) Bernoulli random variables with parameter p. In other words, $X$ is the number of 1s in $n$ Bernoulli trials. You can think of this as the number of heads observed after tossing a coin $n$ times which has probability of heads $p$. Hence for $n=1$, Binomial random variable is equal Bernoulli random variable. \n","\n","Implement a function that simulates m coin tosses by generating m sample values from a Bernoulli distribution. The function takes the probability of heads and m as its arguments and returns an array of 0s and 1s corresponding to the m coin tosses. \n","\n","Hint: You can use [`np.random.binomial()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.binomial.html#numpy.random.binomial) function with $n=1$ to simulate a single coin toss. You can use the `size` argument to repeat the sampling. "]},{"cell_type":"code","metadata":{"id":"Upd1fnKmJnAe","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def coin_toss(m,p):\n","    \n","    # This line makes it sure that the random samples generated are the same in \n","    # different runs of this function. It is only needed for test purposes.  \n","    np.random.seed(seed = 1)\n","\n","    ########## Your Code goes here #############\n","\n","\n","    ############################################\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9oRvHQ2sYi25","colab_type":"code","colab":{}},"source":["project_1_tests.test_coin_toss(coin_toss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WgW9rvAP66z","colab_type":"code","colab":{}},"source":["coin_toss(100, 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dgCNmPcuIfez","colab_type":"text"},"source":["Expected output:\n","\n","```array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n","       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n","       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n","       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n","       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1])```"]},{"cell_type":"markdown","metadata":{"id":"KmkAUHwAMMTk","colab_type":"text"},"source":["# Exercise 11 (5 points)\n","\n","A Multinoulli random variable X is a discrete random variable with k discrete values $c_1, \\ldots, c_k$. The probability distribution is determined by a vector $p = [p_1, \\ldots, p_k]\\in [0,1]^k$ such that $\\sum_i p_i = 1$ and\n","$$\n","\\mathbb{P}(X = c_i) = p_i \\quad i = 1, \\ldots, k\n","$$\n","Think of it as a $k$-sided die roll where the probabilities of each side is given by $p$.\n","\n","A Multinomial random variable $X$ with parameters $n$ and $p\\in [0,1]^k$ is defined as the sum of $n$ independent identically distributed Multinoulli variables. In other words, $X$ is the number of each value in $n$ repetitions of a Multinoulli trial. You can think of it as the frequency of the face values observed after $n$ rolls of a $k$-sided die. A Multinomial random variable with $n=1$ simulates a single die roll. The values taken by such a random variable are vectors consisting of 0s with a single 1 at the index corresponding to the outcome of the die roll. For example, $[0,0,0,1,0,0]$ means that the outcome of the 6-sided die roll was $c_4$. \n","\n","\n","Implement a function that simulates m rolls of an unfair die with k sides numbered 1 through k. The function takes m and the probability vector p as its arguments and returns a 2D array where each row consists of k zeros except a single 1 corresponding to the outcome of the die roll. \n","\n","Hint: You can use [`np.random.multinomial`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.multinomial.html#numpy.random.multinomial) with n = 1. Your solution to Exercise 10 may help. "]},{"cell_type":"code","metadata":{"id":"pso2lianOUR6","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def die_roll(m, p):\n","\n","    np.random.seed(seed = 1)\n","    ########## Your Code goes here #############\n","\n","    ############################################\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUjM3VkdQivU","colab_type":"code","colab":{}},"source":["project_1_tests.test_die_roll(die_roll)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpPLK0OSOyvP","colab_type":"code","colab":{}},"source":["# 30 rolls of a fair die.\n","die_roll(30, [1/6]*6 )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zj3B5KU_InA6","colab_type":"text"},"source":["Expected output:\n","\n","```\n","array([[0, 0, 0, 0, 0, 1],\n","       [0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 1, 0, 0],\n","       [0, 0, 0, 0, 0, 1],\n","       [0, 1, 0, 0, 0, 0],\n","       [1, 0, 0, 0, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [1, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0],\n","       [1, 0, 0, 0, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 0, 0, 1],\n","       [0, 0, 0, 0, 1, 0],\n","       [0, 1, 0, 0, 0, 0],\n","       [0, 1, 0, 0, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [0, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0],\n","       [0, 0, 0, 0, 1, 0],\n","       [0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0],\n","       [0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 0, 1, 0],\n","       [1, 0, 0, 0, 0, 0]])\n","```"]},{"cell_type":"markdown","metadata":{"id":"Lm6yRKeOT3PQ","colab_type":"text"},"source":["# Exercise 12 (5 points)\n","\n","For a discrete random variable $X$ with a probability mass function $P$, the expected value of $X$ is defined as \n","$$\n","\\mathbb{E}[X] = \\sum_xP(x)x\n","$$\n","where the sum is over all possible values of $X$. For a function $f$ defined over the sample space of $X$, the expected value of $f$ with respect to the distribution $P$ is defined as,\n","$$\n","\\mathbb{E}_{x\\sim P}[f(x)] = \\sum_x P(x)f(x)\n","$$\n","\n","Implement a function that computes the expected value of a function with respect to a distribution $P$. The function takes two arguments: \n","  - $f = [f(x_1), \\ldots, f(x_N)]$, a 1D numpy array consisting of the value of the function $f$ at each possible value of $X$\n","  - $P = [p_1, \\ldots, p_N]$, a 1D numpy array consisting of probabilities of each possible value of $X$, i.e. $\\mathbb{P}(X= x_i) = p_i$.\n","\n","and return $\\mathbb{E}_{x\\sim P}[f(x)]$. \n"]},{"cell_type":"code","metadata":{"id":"0VQWP9cfdHrZ","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def expected_value(f, P):\n","    ########## Your Code goes here #############\n","\n","    ############################################\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Hg8E43oWGuT","colab_type":"code","colab":{}},"source":["project_1_tests.test_expected_value(expected_value)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CkEpc-gWwdci","colab_type":"text"},"source":["# Exercise 13 (5 points)\n","\n","Given two probability distributions $P$ and $Q$ over a random variable $X$, a measure of how different these two distributions is given by KL-divergence:\n","$$\n","D_{KL}(P||Q) = \\mathbb{E}_{x\\sim P}[\\log P(x) - \\log Q(x)] = \\mathbb{E}_{x\\sim P}[\\log P(x)] - \\mathbb{E}_{x\\sim P}[\\log Q(x)]\n","$$\n","For example, $P$ could be an empirical distribution given by the observed data from a data generating process and $Q$ could be the distribution modeling this underlying process. Then the KL-divergence is telling us how good is the model $Q$ modeling the underlying process. \n","\n","Implement a function that computes the KL-divergence of two distributions. The function takes two arguments:\n"," - $P$: a 1D numpy array consisting of probabilities with respect to $P$.\n"," - $Q$: a 1D numpy array consisting of probabilities with respect to $Q$. \n","\n","and returns $D_{KL}(P||Q)$.   \n","\n","Hint: The `expected_value` function from Exercise 12 can be helpful. "]},{"cell_type":"code","metadata":{"id":"oc3j8_Suy_4f","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def kl_divergence(P, Q):\n","\n","    ########## Your Code goes here #############\n","\n","\n","    ############################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0q5zzxbY2gsY","colab_type":"code","colab":{}},"source":["project_1_tests.test_kl_divergence(kl_divergence)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BS_03SRNAS9P","colab_type":"text"},"source":["# Exercise 14 (25 points)\n","\n","In this exercise, you will implement the perceptron algorithm through origin. \n","\n","First implement the prediction function that takes the weights $w$ and the input vector $x$ and return the prediction of the model. This function is denoted as $h_{w,0}(x)$ in class and defined as\n","$$\n","h_{w,0}(x) = \\begin{cases}\n","1 \\quad \\text{ if } w\\cdot x \\geq 0 \\\\\n","0 \\quad \\text{ if } w\\cdot x < 0\n","\\end{cases}\n","$$\n","\n","The function takes two arguments $w$ and $x$ and returns 1 or 0 according to the above definition. "]},{"cell_type":"code","metadata":{"id":"b4SgcP2ZASpQ","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def h(w, x):\n","\n","    ########## Your Code goes here #############\n","\n","    \n","    ############################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbdzP4QenKsV","colab_type":"code","colab":{}},"source":["project_1_tests.test_prediction(h)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oGufyO1CCRKk","colab_type":"text"},"source":["Now you will implement the perceptron algorithm through the origin. Below function takes the training data and the labels as arguments and return the learned weights. The training loop is already given, it loops over the training data 10 times. Implement the weight update step:\n","$$\n","w = w - (-1)^{y^{(i)}}x^{(i)}\n","$$\n","if the $i$th example is misclassified. If the $i$th example is classified correctly, $w$ is not updated. \n","\n","`x_train` below is a 2D numpy array of shape $(2,n)$ where $n$ is the number of training examples. Each row of `x_train` is an example in training data. You can get the $i$th example $x^{(i)}$ as `x_train[i]` and the corresponding label $y^{(i)}$ as `y_train[i]`. Use the prediction function, h, you implemented above to check if a given example is misclassified. "]},{"cell_type":"code","metadata":{"id":"6mCaIusWCPgP","colab_type":"code","colab":{}},"source":["def perceptron_through_origin(x_train,y_train):\n","    #number of data points\n","    num_data = len(x_train)\n","\n","    #initialize the weights\n","    w = np.array([0,0])\n","\n","    for i in range(10):\n","        for i in range(num_data):\n","            ########## Your Code goes here #############\n","            #TODO: Check if the ith example is misclassified and update w if it is.\n","\n","            ############################################\n","    return w"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LR57-obAExrh","colab_type":"code","colab":{}},"source":["project_1_tests.test_perceptron(perceptron_through_origin)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PK-PmkL7FVEP","colab_type":"text"},"source":["Let's apply the perceptron algorithm you implemented above. The following code cell is loading an artificial dataseet and plotting it. "]},{"cell_type":"code","metadata":{"id":"A8QdzMceE2mg","colab_type":"code","colab":{}},"source":["x_train, y_train = project_1_utils.load_data()\n","project_1_utils.plot_data(x_train,y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VSCMj6m1Fvkt","colab_type":"text"},"source":["Now run the perceptron algorithm on this dataset and get the weights learned by the algorithm."]},{"cell_type":"code","metadata":{"id":"UMDfoezpFuZP","colab_type":"code","colab":{}},"source":["w = perceptron_through_origin(x_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SSX9hDe6F92M","colab_type":"text"},"source":["Let's plot the decision boundary learned by the algorithm. "]},{"cell_type":"code","metadata":{"id":"WIsZalXfF8X_","colab_type":"code","colab":{}},"source":["project_1_utils.plot_data(x_train, y_train)\n","project_1_utils.plot_decision_boundary(w)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKYsqoq5GIM2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}